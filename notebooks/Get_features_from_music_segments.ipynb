{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import csv\n",
    "import datetime\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, merge\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUDIO_PATH = '/root/HSE_final/segm/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "musicDir = os.listdir(AUDIO_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrograms_new(filelist):\n",
    "    print(\"Reading and processing\", len(filelist), \"audio files\")\n",
    "    q = data_loader.SpectrogramParser({'sample_rate':16000,'window_size':0.015,'window_stride':0.0039,'window':'hamming'},normalize='max_frame')\n",
    "    list_spectrograms = []\n",
    "    for i in tqdm_notebook(range(len(filelist))):\n",
    "        sample = filelist[i]\n",
    "        filepath = os.path.join(AUDIO_PATH, sample)\n",
    "        e = q.parse_audio(filepath)\n",
    "        list_spectrograms.append(np.append(e.numpy(),np.full((121, 2), e.numpy().mean(), dtype='float32'), axis = 1))\n",
    "        #list_spectrograms.append(e.numpy())\n",
    "    return list_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41a4eb999097493e8abcd1a6017ce791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing 125 audio files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bd358edab74c08a56f27fc650120fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and processing 1602 audio files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3058617e42d3450b9fc144dbd5bb03ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for types in tqdm_notebook(musicDir):\n",
    "    list_of_files = []\n",
    "    list_of_names = []\n",
    "    for i in os.listdir(AUDIO_PATH + '/' + types):\n",
    "        if i!= '.ipynb_checkpoints':\n",
    "            list_of_files.append(AUDIO_PATH +'/'+ types+ '/' + i)\n",
    "            list_of_names.append(i.split('.')[0])\n",
    "    data = create_spectrograms_new(list_of_files)\n",
    "    data = np.stack(data, axis=0 )\n",
    "    data = standardize(data)\n",
    "    data = add_channel(data, n_channels=1)\n",
    "    if data.shape[0] > 1100:\n",
    "        layer_output_1 = nn_2_way([data[:1100]])\n",
    "        layer_output_2 = nn_2_way([data[1100:]])\n",
    "        layer_output = []\n",
    "        layer_output.append(np.concatenate((layer_output_1[0],layer_output_2[0]), axis = 0))\n",
    "        layer_output.append(np.concatenate((layer_output_1[1],layer_output_2[1]), axis = 0))\n",
    "    else:\n",
    "        layer_output = nn_2_way([data])\n",
    "    os.mkdir('/root/HSE_final/features/audio/'+types)\n",
    "    for i in range(len(layer_output[0])):\n",
    "        list_pickles = []\n",
    "        with open('/root/HSE_final/features/audio/'+types + '/'+list_of_names[i]+'.pickle', 'wb') as f:\n",
    "            list_pickles.append(layer_output[0][i])\n",
    "            list_pickles.append(layer_output[1][i])\n",
    "            pickle.dump(list_pickles, f)\n",
    "         \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(data):\n",
    "    # vectorize before standardization (cause scaler can't do it in that format)\n",
    "    N, ydim, xdim = data.shape\n",
    "    data = data.reshape(N, xdim*ydim)\n",
    "\n",
    "    # standardize\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    data = scaler.fit_transform(data)\n",
    "\n",
    "    # reshape to original shape\n",
    "    return data.reshape(N, ydim, xdim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_channel(data, n_channels=1):\n",
    "    # n_channels: 1 for grey-scale, 3 for RGB, but usually already present in the data\n",
    "    \n",
    "    N, ydim, xdim = data.shape\n",
    "    data = data.reshape(N, ydim, xdim, n_channels)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "metrics = ['accuracy', precision, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_2_way = K.function([model.layers[0].input],\n",
    "                    [model.layers[-2].output,model.layers[-3].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('my_model.h5',custom_objects={'precision': precision,'recall':recall})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 121, 1451, 1)      0         \n",
      "_________________________________________________________________\n",
      "bn_0_freq (BatchNormalizatio (None, 121, 1451, 1)      5804      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 1451, 64)     640       \n",
      "_________________________________________________________________\n",
      "bn1 (BatchNormalization)     (None, 121, 1451, 64)     256       \n",
      "_________________________________________________________________\n",
      "elu_1 (ELU)                  (None, 121, 1451, 64)     0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 60, 362, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 60, 362, 64)       36928     \n",
      "_________________________________________________________________\n",
      "bn2 (BatchNormalization)     (None, 60, 362, 64)       256       \n",
      "_________________________________________________________________\n",
      "elu_2 (ELU)                  (None, 60, 362, 64)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 15, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 15, 90, 64)        36928     \n",
      "_________________________________________________________________\n",
      "bn3 (BatchNormalization)     (None, 15, 90, 64)        256       \n",
      "_________________________________________________________________\n",
      "elu_3 (ELU)                  (None, 15, 90, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling2D)         (None, 3, 18, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 18, 128)        73856     \n",
      "_________________________________________________________________\n",
      "bn4 (BatchNormalization)     (None, 3, 18, 128)        512       \n",
      "_________________________________________________________________\n",
      "elu_4 (ELU)                  (None, 3, 18, 128)        0         \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling2D)         (None, 1, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 221,745\n",
      "Trainable params: 218,203\n",
      "Non-trainable params: 3,542\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

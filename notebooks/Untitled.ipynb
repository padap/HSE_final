{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan:\n",
    "    1. Fit and predict on small data\n",
    "        - random ID\n",
    "        - n pos - y=1, k negy=0\n",
    "    2. Keras batch loader\n",
    "    3. Normal siamse network realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 108400 samples, validate on 17820 samples\n",
      "Epoch 1/20\n",
      "108400/108400 [==============================] - 13s 120us/step - loss: 0.0969 - accuracy: 0.8844 - val_loss: 0.0443 - val_accuracy: 0.9560\n",
      "Epoch 2/20\n",
      "108400/108400 [==============================] - 11s 99us/step - loss: 0.0414 - accuracy: 0.9602 - val_loss: 0.0312 - val_accuracy: 0.9695\n",
      "Epoch 3/20\n",
      "108400/108400 [==============================] - 11s 99us/step - loss: 0.0283 - accuracy: 0.9715 - val_loss: 0.0260 - val_accuracy: 0.9699\n",
      "Epoch 4/20\n",
      "108400/108400 [==============================] - 11s 98us/step - loss: 0.0221 - accuracy: 0.9768 - val_loss: 0.0257 - val_accuracy: 0.9716\n",
      "Epoch 5/20\n",
      "108400/108400 [==============================] - 11s 99us/step - loss: 0.0187 - accuracy: 0.9803 - val_loss: 0.0214 - val_accuracy: 0.9757\n",
      "Epoch 6/20\n",
      "108400/108400 [==============================] - 10s 94us/step - loss: 0.0165 - accuracy: 0.9828 - val_loss: 0.0224 - val_accuracy: 0.9737\n",
      "Epoch 7/20\n",
      "108400/108400 [==============================] - 10s 89us/step - loss: 0.0148 - accuracy: 0.9843 - val_loss: 0.0219 - val_accuracy: 0.9742\n",
      "Epoch 8/20\n",
      "108400/108400 [==============================] - 10s 93us/step - loss: 0.0140 - accuracy: 0.9850 - val_loss: 0.0238 - val_accuracy: 0.9727\n",
      "Epoch 9/20\n",
      "108400/108400 [==============================] - 11s 104us/step - loss: 0.0127 - accuracy: 0.9864 - val_loss: 0.0226 - val_accuracy: 0.9736\n",
      "Epoch 10/20\n",
      "108400/108400 [==============================] - 11s 101us/step - loss: 0.0119 - accuracy: 0.9871 - val_loss: 0.0214 - val_accuracy: 0.9763\n",
      "Epoch 11/20\n",
      "108400/108400 [==============================] - 11s 97us/step - loss: 0.0114 - accuracy: 0.9876 - val_loss: 0.0225 - val_accuracy: 0.9737\n",
      "Epoch 12/20\n",
      "108400/108400 [==============================] - 11s 97us/step - loss: 0.0106 - accuracy: 0.9887 - val_loss: 0.0225 - val_accuracy: 0.9758\n",
      "Epoch 13/20\n",
      "108400/108400 [==============================] - 11s 97us/step - loss: 0.0102 - accuracy: 0.9891 - val_loss: 0.0224 - val_accuracy: 0.9745\n",
      "Epoch 14/20\n",
      "108400/108400 [==============================] - 10s 93us/step - loss: 0.0101 - accuracy: 0.9891 - val_loss: 0.0222 - val_accuracy: 0.9744\n",
      "Epoch 15/20\n",
      "108400/108400 [==============================] - 10s 89us/step - loss: 0.0095 - accuracy: 0.9900 - val_loss: 0.0230 - val_accuracy: 0.9732\n",
      "Epoch 16/20\n",
      "108400/108400 [==============================] - 10s 93us/step - loss: 0.0092 - accuracy: 0.9903 - val_loss: 0.0230 - val_accuracy: 0.9740\n",
      "Epoch 17/20\n",
      "108400/108400 [==============================] - 11s 97us/step - loss: 0.0089 - accuracy: 0.9905 - val_loss: 0.0236 - val_accuracy: 0.9740\n",
      "Epoch 18/20\n",
      "108400/108400 [==============================] - 10s 96us/step - loss: 0.0090 - accuracy: 0.9905 - val_loss: 0.0238 - val_accuracy: 0.9723\n",
      "Epoch 19/20\n",
      "108400/108400 [==============================] - 10s 97us/step - loss: 0.0086 - accuracy: 0.9909 - val_loss: 0.0231 - val_accuracy: 0.9733\n",
      "Epoch 20/20\n",
      "108400/108400 [==============================] - 10s 93us/step - loss: 0.0090 - accuracy: 0.9903 - val_loss: 0.0238 - val_accuracy: 0.9718\n",
      "* Accuracy on training set: 99.54%\n",
      "* Accuracy on test set: 97.18%\n"
     ]
    }
   ],
   "source": [
    "'''Trains a Siamese MLP on pairs of digits from the MNIST dataset.\n",
    "It follows Hadsell-et-al.'06 [1] by computing the Euclidean distance on the\n",
    "output of the shared network and by optimizing the contrastive loss (see paper\n",
    "for more details).\n",
    "# References\n",
    "- Dimensionality Reduction by Learning an Invariant Mapping\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "Gets to 97.2% test accuracy after 20 epochs.\n",
    "2 seconds per epoch on a Titan X Maxwell GPU\n",
    "'''\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, Lambda\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    square_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * square_pred + (1 - y_true) * margin_square)\n",
    "\n",
    "\n",
    "def create_pairs(x, digit_indices):\n",
    "    '''Positive and negative pair creation.\n",
    "    Alternates between positive and negative pairs.\n",
    "    '''\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    n = min([len(digit_indices[d]) for d in range(num_classes)]) - 1\n",
    "    for d in range(num_classes):\n",
    "        for i in range(n):\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[d][i + 1]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            inc = random.randrange(1, num_classes)\n",
    "            dn = (d + inc) % num_classes\n",
    "            z1, z2 = digit_indices[d][i], digit_indices[dn][i]\n",
    "            pairs += [[x[z1], x[z2]]]\n",
    "            labels += [1, 0]\n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\n",
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "\n",
    "def compute_accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_true)\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))\n",
    "\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# create training+test positive and negative pairs\n",
    "digit_indices = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "tr_pairs, tr_y = create_pairs(x_train, digit_indices)\n",
    "\n",
    "digit_indices = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "te_pairs, te_y = create_pairs(x_test, digit_indices)\n",
    "\n",
    "# network definition\n",
    "base_network = create_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "# because we re-use the same instance `base_network`,\n",
    "# the weights of the network\n",
    "# will be shared across the two branches\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "\n",
    "# train\n",
    "rms = RMSprop()\n",
    "model.compile(loss=contrastive_loss, optimizer=rms, metrics=[accuracy])\n",
    "model.fit([tr_pairs[:, 0], tr_pairs[:, 1]], tr_y,\n",
    "          batch_size=128,\n",
    "          epochs=epochs,\n",
    "          validation_data=([te_pairs[:, 0], te_pairs[:, 1]], te_y))\n",
    "\n",
    "# compute final accuracy on training and test sets\n",
    "y_pred = model.predict([tr_pairs[:, 0], tr_pairs[:, 1]])\n",
    "tr_acc = compute_accuracy(tr_y, y_pred)\n",
    "y_pred = model.predict([te_pairs[:, 0], te_pairs[:, 1]])\n",
    "te_acc = compute_accuracy(te_y, y_pred)\n",
    "\n",
    "print('* Accuracy on training set: %0.2f%%' % (100 * tr_acc))\n",
    "print('* Accuracy on test set: %0.2f%%' % (100 * te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17820, 2, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(input_shape):\n",
    "    '''Base network to be shared (eq. to feature extraction).\n",
    "    '''\n",
    "    input = Input(shape=input_shape)\n",
    "    x = Flatten()(input)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    return Model(input, x)\n",
    "\n",
    "base_network = create_base_network(input_shape)\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance,\n",
    "                  output_shape=eucl_dist_output_shape)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
